{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the notebook for the main project of Advanced Learning Model:\n",
    "\n",
    "- **./data/train** contain data necessary for training\n",
    "- **./data/test** contain data necessary for test\n",
    "- **./main** will contain the main script used to create and train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading training features and concatenate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training():\n",
    "    import csv\n",
    "\n",
    "    clean_features = []\n",
    "\n",
    "    with open('./data/train/Xtr0.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            clean_features.append(list(row[0].replace(\"\\n\", \"\")))\n",
    "\n",
    "    with open('./data/train/Xtr1.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            clean_features.append(list(row[0].replace(\"\\n\", \"\")))\n",
    "\n",
    "    with open('./data/train/Xtr2.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            clean_features.append(list(row[0].replace(\"\\n\", \"\")))\n",
    "\n",
    "    print (\"N. samples: \" + str(len(clean_features)))\n",
    "    \n",
    "    clean_labels = []\n",
    "\n",
    "    with open('./data/train/Ytr0.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = True;\n",
    "        for row in reader:\n",
    "            if header == True:\n",
    "                header = False\n",
    "            else:\n",
    "                clean_labels.append(int(row[1].replace(\"\\n\", \"\")))\n",
    "\n",
    "    with open('./data/train/Ytr1.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = True;\n",
    "        for row in reader:\n",
    "            if header == True:\n",
    "                header = False\n",
    "            else:\n",
    "                clean_labels.append(int(row[1].replace(\"\\n\", \"\")))\n",
    "\n",
    "    with open('./data/train/Ytr2.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = True;\n",
    "        for row in reader:\n",
    "            if header == True:\n",
    "                header = False\n",
    "            else:\n",
    "                clean_labels.append(int(row[1].replace(\"\\n\", \"\")))\n",
    "                \n",
    "                \n",
    "    print (\"N. labels: \" + str(len(clean_labels)))   \n",
    "    return (clean_features, clean_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test():\n",
    "    import csv\n",
    "\n",
    "    clean_features_test = []\n",
    "\n",
    "    with open('./data/test/Xte0.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            clean_features_test.append(list(row[0].replace(\"\\n\", \"\")))\n",
    "\n",
    "    with open('./data/test/Xte1.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            clean_features_test.append(list(row[0].replace(\"\\n\", \"\")))\n",
    "\n",
    "    with open('./data/test/Xte2.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            clean_features_test.append(list(row[0].replace(\"\\n\", \"\")))\n",
    "\n",
    "    print (\"N. test samples: \" + str(len(clean_features_test)))\n",
    "    return clean_features_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some useful functions:\n",
    "- **get_frequencies(X)** return features of dimension 4 having each the count of each gene (countA, countC, countG, countT)\n",
    "- **get_encoded(X)** return features of dimension 100 substituting at each position the number for the corresponding gene (A=1, C=2, G=3, T=4)\n",
    "- **get_spectrum_space(X, n)** return the feature mapping with sequences n\n",
    "- **def get_spectrum_space_boost(X, n):** return the feature mapping with sequences n, n-1 ... 1\n",
    "- **get_nonzero_labels(y)** return labels -1/+1\n",
    "- **get_zero_labels(y)** return labels 0/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequencies(clean_features):\n",
    "    freqCount = []\n",
    "    for i in range(0, len(clean_features)):\n",
    "    \n",
    "        countA = 0\n",
    "        countC = 0\n",
    "        countG = 0\n",
    "        countT = 0\n",
    "\n",
    "        for j in range(0, len(clean_features[i])):\n",
    "\n",
    "            if clean_features[i][j] == \"A\":\n",
    "                countA = countA + 1\n",
    "            elif clean_features[i][j] == \"C\":\n",
    "                countC = countC + 1\n",
    "            elif clean_features[i][j] == \"G\":\n",
    "                countG = countG + 1\n",
    "            else:\n",
    "                countT = countT + 1\n",
    "\n",
    "        freqCount.append([countA, countC, countG, countT])\n",
    "    \n",
    "    return freqCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoded(clean_features):\n",
    "    encoded = []\n",
    "    for i in range(0, len(clean_features)):\n",
    "        tmp_encoded = []\n",
    "        for j in range(0, len(clean_features[i])):\n",
    "            \n",
    "            if clean_features[i][j] == \"A\":\n",
    "                tmp_encoded.append(1)\n",
    "            elif clean_features[i][j] == \"C\":\n",
    "                tmp_encoded.append(2)\n",
    "            elif clean_features[i][j] == \"G\":\n",
    "                tmp_encoded.append(3)\n",
    "            else:\n",
    "                tmp_encoded.append(4)\n",
    "\n",
    "        encoded.append(tmp_encoded)\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nplet_list(n=3):\n",
    "    from itertools import product\n",
    "    nplets = []\n",
    "    t =  product('ACTG', repeat=n)\n",
    "    for i in t: \n",
    "        nplets.append(''.join(i))\n",
    "    return nplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_space_boost(clean_features, n=3):\n",
    "    \n",
    "    import numpy as np\n",
    "    import copy\n",
    "    \n",
    "    triplets = []\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        triplets = triplets + get_nplet_list(i)\n",
    "    \n",
    "    features = copy.copy(clean_features)\n",
    "    \n",
    "    if (len(features) <= 1):\n",
    "        for i in range(0, len(features)):\n",
    "            features[i] = list(features[i])\n",
    "\n",
    "    new_features = np.zeros((len(features), len(triplets)))\n",
    "    \n",
    "    for j in range(0, len(features)):\n",
    "        for i in range(0, len(features[j])-(n-1)):\n",
    "            ts = \"\"\n",
    "            for k in range(0, n):\n",
    "                ts= ts + features[j][i+k]\n",
    "            new_features[j][triplets.index(ts)] = new_features[j][triplets.index(ts)] + 1\n",
    "\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_space(clean_features, n=3):\n",
    "    \n",
    "    import numpy as np\n",
    "    import copy\n",
    "    \n",
    "    triplets = get_nplet_list(n)\n",
    "    \n",
    "    features = copy.copy(clean_features)\n",
    "    \n",
    "    if (len(features) <= 1):\n",
    "        for i in range(0, len(features)):\n",
    "            features[i] = list(features[i])\n",
    "\n",
    "    new_features = np.zeros((len(features), len(triplets)))\n",
    "    \n",
    "    for j in range(0, len(features)):\n",
    "        for i in range(0, len(features[j])-(n-1)):\n",
    "            ts = \"\"\n",
    "            for k in range(0, n):\n",
    "                ts= ts + features[j][i+k]\n",
    "            new_features[j][triplets.index(ts)] = new_features[j][triplets.index(ts)] + 1\n",
    "\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonzero_labels(clean_labels):\n",
    "    new_labels = []\n",
    "    \n",
    "    for i in clean_labels:\n",
    "        if (i==1):\n",
    "            new_labels.append(1)\n",
    "        else:\n",
    "            new_labels.append(-1)\n",
    "    \n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_labels(clean_labels):\n",
    "    new_labels = []\n",
    "    \n",
    "    for i in clean_labels:\n",
    "        if (i==1):\n",
    "            new_labels.append(1)\n",
    "        else:\n",
    "            new_labels.append(0)\n",
    "    \n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hideOutput": false
   },
   "outputs": [],
   "source": [
    "clean_features, clean_labels = get_training()\n",
    "clean_features_test = get_test()\n",
    "triplet_features = get_triplet_space(clean_features, n=7)\n",
    "X_report_test = get_triplet_space(clean_features_test, n=7)\n",
    "non_zero_labels = get_nonzero_labels(clean_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cell used during development to random split the training set in train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import *\n",
    "X_train, X_test, y_train, y_test = train_test_split(triplet_features, non_zero_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernel:\n",
    "    # wrapper class for different kernels\n",
    "    def __init__(self, kernel=\"rbf\", gamma=0.1, degree=3, sigma=5.0, offset=0.0):\n",
    "        self._kernel = kernel\n",
    "        self._gamma = gamma\n",
    "        self._degree = degree\n",
    "        self._sigma = sigma\n",
    "        self._offset = offset\n",
    "        self._function = self._kfunction(kernel)\n",
    "        return\n",
    "    \n",
    "    def kernel_function(self):\n",
    "        return self._function\n",
    "    \n",
    "    def _kfunction(self, kernel):\n",
    "        \n",
    "        if kernel == \"linear\": # Linear Kernel\n",
    "            \n",
    "            def f(x, y):\n",
    "                return np.inner(x, y)\n",
    "            return f\n",
    "        \n",
    "        elif kernel == \"rbf\": # Radial Basis Function Kernel\n",
    "            \n",
    "            def f(x, y):\n",
    "                exponent = - self._gamma * np.linalg.norm(x-y) ** 2\n",
    "                return np.exp(exponent)\n",
    "            return f\n",
    "            \n",
    "        elif kernel == \"quadratic\": # Quadratic Kernel\n",
    "            \n",
    "            def f(x, y):\n",
    "                return (self._gamma * (self._offset + np.dot(x, y))) ** 2\n",
    "            return f\n",
    "        \n",
    "        elif kernel == \"polynomial\": # Polynomial Kernel\n",
    "            \n",
    "            def f(x, y):\n",
    "                return (self._gamma * (self._offset + np.dot(x, y))) ** self._degree\n",
    "            return f\n",
    "        \n",
    "        elif kernel == \"gaussian\": # real Gaussian Kernel\n",
    "            \n",
    "            def f(x, y):\n",
    "                return np.exp(-linalg.norm(x-y)**2 / (2 * (self._sigma ** 2)))\n",
    "            return f\n",
    "    \n",
    "        else:\n",
    "            print (\"[ERROR] The required kernel is not implemented.\")\n",
    "            exit(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM class implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg\n",
    "import cvxopt\n",
    "import cvxopt.solvers\n",
    "\n",
    "\n",
    "class SVM:\n",
    "    # init function for the SVM classifier\n",
    "    def __init__(self, kernel='linear', gamma=0.1, degree=3, C=1.0, offset=0.0, sigma=5.0):\n",
    "        self._kernel_name = kernel\n",
    "        self._offset = offset\n",
    "        self._sigma=sigma\n",
    "        self.kernel = Kernel(kernel, gamma=gamma, degree=degree, offset=offset, sigma=sigma).kernel_function()\n",
    "        self.C = C\n",
    "        if self.C is not None: self.C = float(self.C)\n",
    "            \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X=np.array([np.array(xi) for xi in X])\n",
    "        y=np.array([np.array(yi) for yi in y])\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Computation of the gram matrix\n",
    "        K = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                K[i,j] = self.kernel(X[i], X[j])\n",
    "\n",
    "        P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1,n_samples), 'd')\n",
    "        b = cvxopt.matrix(0.0)\n",
    "\n",
    "        if self.C is None:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else:\n",
    "            tmp1 = np.diag(np.ones(n_samples) * -1)\n",
    "            tmp2 = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))\n",
    "            tmp1 = np.zeros(n_samples)\n",
    "            tmp2 = np.ones(n_samples) * self.C\n",
    "            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))\n",
    "\n",
    "        # Obtaining Lagrange multipliers\n",
    "        solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        a = np.ravel(solution['x'])\n",
    "\n",
    "        # Support vectors have \"non zero\" lagrange multipliers -> threshold = 1e-5\n",
    "        sv = a > 1e-5\n",
    "        ind = np.arange(len(a))[sv]\n",
    "        self.a = a[sv]\n",
    "        self.sv = X[sv]\n",
    "        self.sv_y = y[sv]\n",
    "        print(\"%d support vectors out of %d points\" % (len(self.a), n_samples))\n",
    "        \n",
    "        self.b = 0\n",
    "        for n in range(len(self.a)):\n",
    "            self.b += self.sv_y[n]\n",
    "            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])\n",
    "        self.b /= len(self.a)\n",
    "\n",
    "        if self._kernel_name == 'linear':\n",
    "            self.w = np.zeros(n_features)\n",
    "            for n in range(len(self.a)):\n",
    "                self.w += self.a[n] * self.sv_y[n] * self.sv[n]\n",
    "        else:\n",
    "            self.w = None\n",
    "    \n",
    "    def predict(self, X):\n",
    "        ''' Computes the SVM prediction on the given samples X. '''\n",
    "        return np.sign(self.project(X))\n",
    "        \n",
    "    def project(self, X):\n",
    "        ''' Funtion used for the prediction '''\n",
    "        if self.w is not None:\n",
    "            return np.dot(X, self.w) + self.b\n",
    "        else:\n",
    "            y_predict = np.zeros(len(X))\n",
    "            for i in range(len(X)):\n",
    "                s = 0\n",
    "                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):\n",
    "                    s += a * sv_y * self.kernel(X[i], sv)\n",
    "                y_predict[i] = s\n",
    "            return y_predict + self.b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM(kernel=\"rbf\")\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell used to test during development (test/train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)    \n",
    "correct = np.sum(y_predict == y_test)\n",
    "\n",
    "print(\"[RESULTS] %d out of %d predictions correct, accuracy: %f\" % (correct, len(y_predict), correct/len(y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write test labels on file (result.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_test_labels(clf, X_test, filename=\"result.csv\"):\n",
    "    import csv\n",
    "    \n",
    "    y_predict_test = clf.predict(X_test)\n",
    "    y_predict_test = get_zero_labels(y_predict_test)\n",
    "    \n",
    "    with open(filename, 'w') as csvfile:\n",
    "        fieldnames = ['Id', 'Bound']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for i in range(0, len(y_predict_test)):\n",
    "            writer.writerow({'Id': i, 'Bound': y_predict_test[i]})\n",
    "\n",
    "    print (\"Done, find results on \" + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_test_labels(clf, X_report_test, filename=\"results_s7654321_quadratic_standard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
